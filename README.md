1. Setup environment to crawl
* pip install -r requirement
* install one selenium driver: firefox driver/ I use **chrome driver**/ phantomjs

2. Tested with python 3.7:
* cd Hackathon2020
* python src/utils/foodyDataFeed.py

This base script intent to crawl some data from foody site.

Feature will implement later as request:
* Concurrent.
* Site-wide crawling.
* Reliable storing to DB.
* Sentiment analysis.
* Neo4j DB for user.
* Recommendation for restaurant ads
* Recommendation restaurant for user.
* Recommendation matching user for a date.
-----
* Implement in Java.
